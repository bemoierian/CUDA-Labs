{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###**Intrinsic Functions**\n",
        "- Specialized functions provided by the CUDA programming model. They are callable only from the device. They do not need to include any additional headers in your program.\n",
        "- These functions often offer an alternative to standard functions that are faster but may have less numerical accuracy, they are majorly used in mathematical functions."
      ],
      "metadata": {
        "id": "QeYRECDhwjCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Thread Synchronization**\n",
        "\n",
        "Threads **within a block** can cooperate by sharing data through some shared memory and by synchronizing their execution to coordinate memory accesses. More precisely, one can specify synchronization points in the kernel by calling the __syncthreads() **intrinsic** function; __syncthreads() acts as a barrier at which all threads in the block must wait before any is allowed to proceed"
      ],
      "metadata": {
        "id": "F64T3RiV76Mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# __syncthreads() example\n",
        "\n",
        "  // declares a shared memory segment that is accessible by all threads in the same block. More on this later.\n",
        "__shared__ float partialSum[SIZE];\n",
        "partialSum[threadIdx.x] = X[blockIdx.x * blockDim.x + threadIdx.x];\n",
        "unsigned int t = threadIdx.x;\n",
        "for(unsigned int stride = 1; stride < blockDim.x; stride *= 2){\n",
        "     __syncthreads();\n",
        "     if(t % (2*stride) == 0)\n",
        "          partialSum[t] += partialSum[t+stride];\n",
        "}"
      ],
      "metadata": {
        "id": "lWoqlhY2-1Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The __syncthreads() statement in the for-loop ensures that all partial sums for the previous iteration have been generated and before any one of the threads is allowed to begin the current iteration"
      ],
      "metadata": {
        "id": "drdqiLhiP56h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Thread Divergence**"
      ],
      "metadata": {
        "id": "i-IPfGzZCiEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Consider this example\n",
        "\n",
        "# Does this code work properly? why?\n",
        "if{\n",
        "     ...\n",
        "     __syncthreads();\n",
        "}else{\n",
        "     ...\n",
        "     __syncthreads();\n",
        "}"
      ],
      "metadata": {
        "id": "vu1SU-ZDAnNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If a thread in a block executes the then-path and another executes the else-path, they would be waiting at different barrier synchronization points and end up waiting for each other forever. so if __syncthreads() exists in the kernel, it must be executed by all threads. In this sense, the above code can be fixed as follows:"
      ],
      "metadata": {
        "id": "CCsWXdb5Avci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if{\n",
        "     ...\n",
        "}\n",
        "else{\n",
        "     ...\n",
        "}\n",
        "__syncthreads();"
      ],
      "metadata": {
        "id": "CLY4TIFoCRoL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Requirement 3**\n",
        "\n",
        "A) A cuda program is required to find the sum of an input array as efficiently as possible. The program reads the array elements from an external file (around 10 million floating-point numbers) and prints their sum in the console, **prints nothing more**. Use only 1 block for your kernel.\n",
        "\n",
        "B) A cuda program is required to carry out binary search on an input array. similarly you wil read the input array from a file and the target element as a command line argument. You should use only 1 block and carry out the process efficiently. Print **ONLY** the index of the target number, or -1 if not found.\n",
        "\n",
        "**Check** the samples on the e-learning course page"
      ],
      "metadata": {
        "id": "fla-gd-6K-mn"
      }
    }
  ]
}